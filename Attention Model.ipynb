{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 18:10:12.574092: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "# import keras\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='preprocessed_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pickle.load(open(filename,'rb')) ###open preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3243"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3243"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y= data.iloc[:,1].values\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Manually resolve the tabbed data errors\n",
    "\n",
    "index = [791,  792,  793,  830,  831,  832,  833,  839,  844, 846, 852,  853,\n",
    "         855,  858,  860,  876,  882,  890,  892,  904,  909,  912,  936,\n",
    "         938,  943,  945,  957,  964,  965,  967,  969,  972,  975,  976,\n",
    "        1000, 1007, 1013, 1018, 1297] \n",
    "for i in index:\n",
    "    Y[i] = 0  ###replace value of selected indices of AD column with 0\n",
    "\n",
    "idx = [1072, 1101, 1184, 1244]\n",
    "for i in idx:\n",
    "    Y[i] = 1  ###replace value of selected indices of AD column with 1\n",
    "Y = Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Transcript'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'little girl goin g'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0) ##split the data in training and testing\n",
    "X_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2594\n",
      "649\n",
      "2594\n",
      "649\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train)) ###length of training, testing data\n",
    "print(len(X_test))\n",
    "print(len(Y_train))\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokens(lines):\n",
    "    tokens = Tokenizer()\n",
    "    \n",
    "    ###function to create tokens\n",
    "    tokens.fit_on_texts(lines)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenizer = create_tokens(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save Tokenizer configuration as a JSON string\n",
    "tokenizer_json = train_tokenizer.to_json()\n",
    "\n",
    "# Save Tokenizer JSON string to a file\n",
    "with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(tokenizer_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences(tokens,length,lines):   ###function to pad the data to maximum phrase length\n",
    "    X=tokens.texts_to_sequences(lines)\n",
    "    X=pad_sequences(X,length,padding='post')\n",
    "    return X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  73, 167,  20,   4,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = encode_sentences(train_tokenizer,100, X_train)\n",
    "X_test = encode_sentences(train_tokenizer,100, X_test)\n",
    "X_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.preprocessing.text.Tokenizer object at 0x7f9b2428f9d0>\n"
     ]
    }
   ],
   "source": [
    "print(train_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2594, 100)\n",
      "(649, 100)\n",
      "(2594,)\n",
      "(649,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)   ###check for dimensions\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'uh': 2, 'it': 3, 'cookie': 4, 'g': 5, 'dish': 6, 'water': 7, 'jar': 8, 'mother': 9, 'stool': 10, 'boy': 11, 'little': 12, 'girl': 13, 'sink': 14, 'see': 15, 'window': 16, 'um': 17, 'cooky': 18, 'floor': 19, 'reaching': 20, 'look': 21, 'like': 22, 'running': 23, 'standing': 24, 'drying': 25, 'open': 26, 'fall': 27, 'cup': 28, 'getting': 29, 'laugh': 30, 'overflowing': 31, 'one': 32, 'oh': 33, 'kitchen': 34, 'hand': 35, 'going': 36, 'falling': 37, 'get': 38, 'well': 39, 'gonna': 40, 'two': 41, 'curtain': 42, 'know': 43, 'plate': 44, 'washing': 45, 'xxx': 46, 'think': 47, 'kid': 48, 'looking': 49, 'counter': 50, 'outside': 51, 'sister': 52, 'door': 53, 'f': 54, 'let': 55, 'r': 56, 'want': 57, 'anything': 58, 'onto': 59, 'child': 60, 'foot': 61, 'house': 62, 'lady': 63, 'guess': 64, 'something': 65, 'okay': 66, 'tree': 67, 'else': 68, 'cupboard': 69, 'thing': 70, 'maybe': 71, 'tell': 72, 'also': 73, 'saying': 74, 'right': 75, 'cabinet': 76, 'lid': 77, 'three': 78, 'exc': 79, 'say': 80, 'another': 81, 'left': 82, 'got': 83, 'faucet': 84, 'wet': 85, 'said': 86, 'did': 87, 'goin': 88, 'ready': 89, 'trying': 90, 'must': 91, 'blowing': 92, 'saucer': 93, 'seems': 94, 'summer': 95, 'shh': 96, 'handing': 97, 'back': 98, 'breeze': 99, 'cause': 100, 'apparently': 101, 'w': 102, 'run': 103, 'grass': 104, 'tipping': 105, 'chair': 106, 'coming': 107, 'wiping': 108, 'dryin': 109, 'give': 110, 'next': 111, 'short': 112, 'go': 113, 'woman': 114, 'taking': 115, 'x': 116, 'full': 117, 'stealing': 118, 'side': 119, 'p': 120, 'quiet': 121, 'mean': 122, 'picture': 123, 'action': 124, 'finger': 125, 'clear': 126, 'n': 127, 'gram': 128, 'laughing': 129, 'yeah': 130, 'gettin': 131, 'ret': 132, 'throat': 133, 'mouth': 134, 'th': 135, 'garage': 136, 'mhm': 137, 'spilling': 138, 'brother': 139, 'alright': 140, 'kind': 141, 'sitting': 142, 'shoe': 143, 'tryin': 144, 'would': 145, 'already': 146, 'puddle': 147, 'garden': 148, 'hm': 149, 'bush': 150, 'yard': 151, 'start': 152, 'shrubbery': 153, 'call': 154, 'part': 155, 'turn': 156, 'day': 157, 'runnin': 158, 'telling': 159, 'fell': 160, 'trunk': 161, 'come': 162, 'somebody': 163, 'still': 164, 'blowin': 165, 'place': 166, 'time': 167, 'lip': 168, 'walk': 169, 'course': 170, 'splashing': 171, 'washin': 172, 'bit': 173, 'either': 174, 'everything': 175, 'takin': 176, 'hear': 177, 'stepping': 178, 'oblivious': 179, 'happening': 180, 'mama': 181, 'fallin': 182, 'summertime': 183, 'warm': 184, 'much': 185, 'letting': 186, 'turned': 187, 'shrub': 188, 'top': 189, 'wind': 190, 'might': 191, 'attention': 192, 'wash': 193, 'handle': 194, 'drape': 195, 'whatever': 196, 'doin': 197, 'sleeve': 198, 'c': 199, 'young': 200, 'tilting': 201, 'probably': 202, 'ladder': 203, 'enough': 204, 'around': 205, 'uk': 206, 'whether': 207, 'sh': 208, 'path': 209, 'couple': 210, 'reachin': 211, 'better': 212, 'k': 213, 'handin': 214, 'nice': 215, 'apron': 216, 'son': 217, 'obviously': 218, 'paying': 219, 'cascading': 220, 'except': 221, 'fact': 222, 'dress': 223, 'sigh': 224, 'forgot': 225, 'sayin': 226, 'almost': 227, 'tripping': 228, 'man': 229, 'climbed': 230, 'tip': 231, 'pretty': 232, 'working': 233, 'pouring': 234, 'ha': 235, 'dried': 236, 'could': 237, 'crooked': 238, 'step': 239, 'legged': 240, 'em': 241, 'first': 242, 'bottom': 243, 'tipped': 244, 'opened': 245, 'youngster': 246, 'year': 247, 'put': 248, 'take': 249, 'growing': 250, 'sort': 251, 'standin': 252, 'seven': 253, 'wearing': 254, 'break': 255, 'really': 256, 'meantime': 257, 'dry': 258, 'cloth': 259, 'overflow': 260, 'starting': 261, 'driveway': 262, 'sandal': 263, 'end': 264, 'even': 265, 'asking': 266, 'broke': 267, 'somethin': 268, 'mistake': 269, 'bowl': 270, 'god': 271, 'daydreaming': 272, 'holding': 273, 'h': 274, 'dripping': 275, 'upsetting': 276, 'overflown': 277, 'shushing': 278, 'seem': 279, 'leaf': 280, 'pathway': 281, 'windo': 282, 'spilled': 283, 'slipping': 284, 'tumble': 285, 'washed': 286, 'whole': 287, 'lot': 288, 'many': 289, 'somewhere': 290, 'tennis': 291, 'corner': 292, 'sometimes': 293, 'though': 294, 'school': 295, 'sake': 296, 'reach': 297, 'building': 298, 'sleeveless': 299, 'lawn': 300, 'finished': 301, 'laughin': 302, 'upside': 303, 'long': 304, 'splashin': 305, 'hair': 306, 'hasta': 307, 'nothing': 308, 'flowing': 309, 'hit': 310, 'slight': 311, 'sunny': 312, 'mess': 313, 'inside': 314, 'jct': 315, 'told': 316, 'b': 317, 'way': 318, 'guy': 319, 'steal': 320, 'fairly': 321, 'slanted': 322, 'word': 323, 'soon': 324, 'overspilling': 325, 'real': 326, 'giving': 327, 'thinking': 328, 'neck': 329, 'including': 330, 'identifying': 331, 'e': 332, 'whoever': 333, 'knocked': 334, 'climbing': 335, 'anyway': 336, 'trouble': 337, 'may': 338, 'moment': 339, 'least': 340, 'lad': 341, 'beginning': 342, 'movement': 343, 'mom': 344, 'outta': 345, 'di': 346, 'anybody': 347, 'wipe': 348, 'cook': 349, 'daughter': 350, 'hard': 351, 'pushed': 352, 'si': 353, 'second': 354, 'shocked': 355, 'head': 356, 'process': 357, 'pourin': 358, 'started': 359, 'sash': 360, 'curved': 361, 'u': 362, 'suppose': 363, 'towel': 364, 'lettin': 365, 'make': 366, 'stealin': 367, 'mind': 368, 'upset': 369, 'believe': 370, 'hurt': 371, 'wee': 372, 'reason': 373, 'beside': 374, 'beat': 375, 'silencing': 376, 'scene': 377, 'page': 378, 'perhaps': 379, 'twin': 380, 'touching': 381, 'wall': 382, 'hot': 383, 'sneaking': 384, 'waitin': 385, 'age': 386, 'pantry': 387, 'noise': 388, 'tidy': 389, 'sposta': 390, 'jerk': 391, 'arm': 392, 'towards': 393, 'ou': 394, 'notice': 395, 'happy': 396, 'gentle': 397, 'catastrophe': 398, 'flower': 399, 'front': 400, 'family': 401, 'father': 402, 'lookin': 403, 'evidently': 404, 'went': 405, 'reacting': 406, 'imagine': 407, 'verb': 408, 'shelf': 409, 'weight': 410, 'correctly': 411, 'gone': 412, 'wait': 413, 'un': 414, 'til': 415, 'glass': 416, 'quite': 417, 'describe': 418, 'laid': 419, 'j': 420, 'hell': 421, 'drop': 422, 'making': 423, 'dressed': 424, 'weather': 425, 'wrong': 426, 'sideways': 427, 'ave': 428, 'air': 429, 'fast': 430, 'terrible': 431, 'moved': 432, 'settin': 433, 'sill': 434, 'find': 435, 'hungry': 436, 'givin': 437, 'l': 438, 'set': 439, 'country': 440, 'leaning': 441, 'certain': 442, 'half': 443, 'st': 444, 'wife': 445, 'clothes': 446, 'people': 447, 'size': 448, 'puttin': 449, 'eat': 450, 'overflowed': 451, 'wipin': 452, 'sharing': 453, 'ov': 454, 'overrunning': 455, 'care': 456, 'distressing': 457, 'bench': 458, 'ssh': 459, 'helping': 460, 'sentence': 461, 'venture': 462, 'wanna': 463, 'pas': 464, 'hundred': 465, 'percent': 466, 'ev': 467, 'coo': 468, 'outdoors': 469, 'pattern': 470, 'overflowin': 471, 'swung': 472, 'table': 473, 'quit': 474, 'insisted': 475, 'cappdf': 476, 'five': 477, 'coffee': 478, 'sleeved': 479, 'irt': 480, 'shirt': 481, 'br': 482, 'rest': 483, 'bitchy': 484, 'ah': 485, 'talkin': 486, 'large': 487, 'seeing': 488, 'wing': 489, 'housewife': 490, 'expect': 491, 'galore': 492, 'read': 493, 'pointin': 494, 'hardly': 495, 'meant': 496, 'flooding': 497, 'op': 498, 'steady': 499, 'neglected': 500, 'shut': 501, 'drapery': 502, 'payed': 503, 'tilty': 504, 'female': 505, 'eight': 506, 'old': 507, 'nine': 508, 'grading': 509, 'talk': 510, 'mop': 511, 'watching': 512, 'dear': 513, 'darling': 514, 'total': 515, 'tha': 516, 'appears': 517, 'draw': 518, 'withdrawn': 519, 'drawn': 520, 'dirty': 521, 'engrossed': 522, 'neither': 523, 'receive': 524, 'forgettin': 525, 'poor': 526, 'bloom': 527, 'plug': 528, 'unusual': 529, 'fixed': 530, 'expecting': 531, 'flat': 532, 'yet': 533, 'special': 534, 'grabbing': 535, 'unaware': 536, 'flu': 537, 'watch': 538, 'distinct': 539, 'tri': 540, 'daft': 541, 'dishwash': 542, 'different': 543, 'tryinto': 544, 'geta': 545, 'distracted': 546, 'done': 547, 'eems': 548, 'male': 549, 'spring': 550, 'calm': 551, 'anymore': 552, 'fluttering': 553, 'lane': 554, 'cou': 555, 'remember': 556, 'eaten': 557, 'beautiful': 558, 'looked': 559, 'keeping': 560, 'cleanin': 561, 'gave': 562, 'eatin': 563, 'unfortunately': 564, 'completely': 565, 'outfitted': 566, 'talking': 567, 'mm': 568, 'checked': 569, 'heard': 570, 'new': 571, 'game': 572, 'play': 573, 'christmas': 574, 'headin': 575, 'disaster': 576, 'parted': 577, 'sock': 578, 'good': 579, 'opposite': 580, 'direction': 581, 'toe': 582, 'stink': 583, 'deciding': 584, 'ahead': 585, 'ta': 586, 'sau': 587, 'shor': 588, 'careless': 589, 'ro': 590, 'tripod': 591, 'yellin': 592, 'important': 593, 'typical': 594, 'allowing': 595, 'work': 596, 'stoo': 597, 'ground': 598, 'behind': 599, 'wondering': 600, 'crash': 601, 'ca': 602, 'unless': 603, 'el': 604, 'continue': 605, 'askin': 606, 'essentially': 607, 'chaos': 608, 'cryin': 609, 'mostly': 610, 'imarriage': 611, 'image': 612, 'person': 613, 'activity': 614, 'anyhow': 615, 'winter': 616, 'hanging': 617, 'friend': 618, 'changin': 619, 'ur': 620, 'sp': 621, 'spilt': 622, 'try': 623, 'tea': 624, 'manicured': 625, 'upper': 626, 'mb': 627, 'whatcha': 628, 'floodin': 629, 'attempt': 630, 'playing': 631, 'number': 632, 'stretch': 633, 'dishwashing': 634, 'sound': 635, 'preoccupied': 636, 'slightly': 637, 'pulled': 638, 'comin': 639, 'pant': 640, 'puffy': 641, 'hoping': 642, 'detail': 643, 'wowie': 644, 'stumblin': 645, 'row': 646, 'knob': 647, 'dropped': 648, 'happeni': 649, 'collapse': 650, 'sudden': 651, 'stepped': 652, 'cockeyed': 653, 'need': 654, 'yes': 655, 'aware': 656, 'shortly': 657, 'falled': 658, 'underneath': 659, 'huh': 660, 'pan': 661, 'pointing': 662, 'knew': 663, 'blind': 664, 'tripodal': 665, 'event': 666, 'accident': 667, 'stop': 668, 'kill': 669, 'gather': 670, 'write': 671, 'mentioned': 672, 'flow': 673, 'overturn': 674, 'line': 675, 'pleasure': 676, 'salient': 677, 'drawer': 678, 'instead': 679, 'hafta': 680, 'managed': 681, 'younger': 682, 'tasty': 683, 'putting': 684, 'ar': 685, 'raising': 686, 'sthat': 687, 'inhales': 688, 'smiling': 689, 'selection': 690, 'attentive': 691, 'swepping': 692, 'proceeding': 693, 'presumably': 694, 'addition': 695, 'instruction': 696, 'mumble': 697, 'laying': 698, 'adjacent': 699, 'oop': 700, 'noticed': 701, 'assuming': 702, 'su': 703, 'suspect': 704, 'hickey': 705, 'bumpin': 706, 'sure': 707, 'cloudy': 708, 'great': 709, 'hum': 710, 'noticing': 711, 'haywire': 712, 'allowed': 713, 'possibly': 714, 'worrying': 715, 'mouse': 716, 'hedge': 717, 'letter': 718, 'extension': 719, 'goodness': 720, 'designate': 721, 'leading': 722, 'mad': 723, 'road': 724, 'drive': 725, 'lunch': 726, 'came': 727, 'lea': 728, 'saw': 729, 'tellin': 730, 'low': 731, 'waisted': 732, 'use': 733, 'rubber': 734, 'glove': 735, 'skin': 736, 'crack': 737, 'nail': 738, 'motioning': 739, 'sings': 740, 'raining': 741, 'plant': 742, 'cake': 743, 'pick': 744, 'gir': 745, 'quietly': 746, 'threesome': 747, 'together': 748, 'aside': 749, 'tippin': 750, 'pull': 751, 'near': 752, 'gotta': 753, 'ruffling': 754, 'etch': 755, 'wanting': 756, 'smile': 757, 'face': 758, 'kol': 759, 'four': 760, 'stall': 761, 'tilted': 762, 'walking': 763, 'angle': 764, 'incomplete': 765, 'sad': 766, 'damn': 767, 'plat': 768, 'pl': 769, 'basically': 770, 'stuff': 771, 'thought': 772, 'attentively': 773, 'possible': 774, 'observant': 775, 'busy': 776, 'splash': 777, 'splashed': 778, 'high': 779, 'pompadour': 780, 'slipper': 781, 'certainly': 782, 'dream': 783, 'world': 784, 'helpin': 785, 'apern': 786, 'bring': 787, 'crashing': 788, 'suds': 789, 'wat': 790, 'filling': 791, 'elbow': 792, 'seen': 793, 'instructing': 794, 'dishwasher': 795, 'pot': 796, 'wa': 797, 'color': 798, 'whispering': 799, 'machine': 800, 'harmed': 801, 'clean': 802, 'pineapple': 803, 'medium': 804, 'karen': 805, 'somewhat': 806, 'obliterated': 807, 'partially': 808, 'gotten': 809, 'hold': 810, 'saved': 811, 'happen': 812, 'bad': 813, 'shape': 814, 'dumb': 815, 'signal': 816, 'sta': 817, 'tiltin': 818, 'flowin': 819, 'reading': 820, 'signing': 821, 'careful': 822, 'backyard': 823, 'grab': 824, 'picking': 825, 'nose': 826, 'drain': 827, 'bandaids': 828, 'petroleum': 829, 'jelly': 830, 'vaseline': 831, 'stopper': 832, 'spigot': 833, 'fry': 834, 'egg': 835, 'morning': 836, 'flying': 837, 'handling': 838, 'daylight': 839, 'leg': 840, 'beckoning': 841, 'excuse': 842, 'taken': 843, 'usual': 844, 'husband': 845, 'elsewhere': 846}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "847"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_tokenizer.word_index) ###print the word index\n",
    "vocab_len= len(train_tokenizer.word_index ) + 1 \n",
    "vocab_len   ###vocab length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention MODEL - Case 1: Training the model using randomly initialized embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM, Bidirectional, Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_input = tf.keras.Input(shape=(100,))\n",
    "e = Embedding(vocab_len, 100, input_length= 100)(seq_input)\n",
    "conv1 = Conv1D(filters=128,kernel_size=5,activation='relu',strides= 1, kernel_initializer='he_uniform')(e)\n",
    "pool = MaxPooling1D(pool_size=2)(conv1)\n",
    "dropout= Dropout(0.5)(pool)\n",
    "lstm1 = Bidirectional(LSTM(10, return_sequences=True))(dropout)\n",
    "att=attention()(lstm1)\n",
    "dense1 = Dense(units = 20, activation='relu', kernel_initializer='he_uniform')(att)\n",
    "output= Dense(units = 1, activation = 'sigmoid', kernel_initializer= 'glorot_uniform')(dense1)\n",
    "model=tf.keras.Model(seq_input,output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attention_history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:873\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 873\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    876\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    877\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 694\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    699\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:176\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 176\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    169\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:398\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    396\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 398\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:305\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    304\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 305\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    316\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1055\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1052\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1054\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1055\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:597\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    594\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 597\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/kh/vdy6c9ns1vd57z02v4h_6b4h0000gn/T/__autograph_generated_file16k3qe82.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/keras/src/engine/training.py:1322\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1319\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1322\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1324\u001b[0m     outputs,\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1326\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1327\u001b[0m )\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1669\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1672\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3250\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3248\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:4048\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4046\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4047\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4048\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/keras/src/engine/training.py:1303\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1303\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/keras/src/engine/training.py:1084\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py:543\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py:276\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:1063\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1057\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1058\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1059\u001b[0m           output_gradients))\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1061\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1063\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1072\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:336\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._backward.<locals>._backward_function\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backward_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    335\u001b[0m   call_op \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mop\n\u001b[0;32m--> 336\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rewrite_forward_and_call_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:239\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._rewrite_forward_and_call_backward\u001b[0;34m(self, op, *doutputs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rewrite_forward_and_call_backward\u001b[39m(\u001b[38;5;28mself\u001b[39m, op, \u001b[38;5;241m*\u001b[39mdoutputs):\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m   forward_function, backwards_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdoutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backwards_function\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m backwards_function\u001b[38;5;241m.\u001b[39mstructured_outputs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:172\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions.forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m forward_backward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m forward_backward\n\u001b[0;32m--> 172\u001b[0m forward, backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_forward_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_doutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_function_pairs[num_doutputs] \u001b[38;5;241m=\u001b[39m (forward, backward)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward, backward\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:215\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m    213\u001b[0m   backwards_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mFuncGraph(\n\u001b[1;32m    214\u001b[0m       _backward_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m--> 215\u001b[0m   \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackwards_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpython_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_backprop_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m      \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackwards_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m   backwards_graph_captures \u001b[38;5;241m=\u001b[39m backwards_graph\u001b[38;5;241m.\u001b[39mexternal_captures\n\u001b[1;32m    222\u001b[0m   captures_from_forward \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    223\u001b[0m       c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m backwards_graph_captures \u001b[38;5;28;01mif\u001b[39;00m\n\u001b[1;32m    224\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, ops\u001b[38;5;241m.\u001b[39mEagerTensor) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1055\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1052\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1054\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1055\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:206\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._construct_forward_backward.<locals>._backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backprop_function\u001b[39m(\u001b[38;5;241m*\u001b[39mgrad_ys):\n\u001b[1;32m    205\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgradients_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GradientsHelper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_ys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_ys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:687\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m src_graph\u001b[38;5;241m.\u001b[39m_original_op(op):\n\u001b[1;32m    683\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    684\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[0;32m--> 687\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m \u001b[43m_MaybeCompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_scope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    693\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:327\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    324\u001b[0m     xla_compile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xla_compile:\n\u001b[0;32m--> 327\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exit early\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# together with the non-gradient computation.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:688\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m src_graph\u001b[38;5;241m.\u001b[39m_original_op(op):\n\u001b[1;32m    683\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    684\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 688\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    693\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py:368\u001b[0m, in \u001b[0;36m_WhileGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# We compute the gradient for the sub-graph between trainable ys and xs\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# with non-None incoming gradients. We later pad the None's to the list of\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# outputs.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m ys, xs, non_none_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[(y, x, grad) \u001b[38;5;28;01mfor\u001b[39;00m (y, x, grad) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    366\u001b[0m     body_graph\u001b[38;5;241m.\u001b[39moutputs, body_graph\u001b[38;5;241m.\u001b[39minputs, grads) \u001b[38;5;28;01mif\u001b[39;00m grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[0;32m--> 368\u001b[0m body_grad_graph, args \u001b[38;5;241m=\u001b[39m \u001b[43m_create_grad_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_none_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_grad_fn_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m body_grad_graph\u001b[38;5;241m.\u001b[39mwhile_op_needs_rewrite:\n\u001b[1;32m    373\u001b[0m   \u001b[38;5;66;03m# Modify 'op' to output the intermediate accumulators needed by the grad\u001b[39;00m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;66;03m# function.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m   \u001b[38;5;66;03m# NOTE(skyewm): if there are any active sessions, this modification to `op`\u001b[39;00m\n\u001b[1;32m    376\u001b[0m   \u001b[38;5;66;03m# may make them unrunnable!\u001b[39;00m\n\u001b[1;32m    378\u001b[0m   cond_graph\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_rewritten\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py:664\u001b[0m, in \u001b[0;36m_create_grad_func\u001b[0;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations)\u001b[0m\n\u001b[1;32m    661\u001b[0m args \u001b[38;5;241m=\u001b[39m [counter, maximum_iterations, total_iters] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(grads)\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# `external_captures`.\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m grad_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_WhileBodyGradFuncGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhile_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbody_graph_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;66;03m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m external_capture, internal_capture \u001b[38;5;129;01min\u001b[39;00m grad_func_graph\u001b[38;5;241m.\u001b[39mcaptures:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1055\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1052\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1054\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1055\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py:666\u001b[0m, in \u001b[0;36m_create_grad_func.<locals>.<lambda>\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    661\u001b[0m args \u001b[38;5;241m=\u001b[39m [counter, maximum_iterations, total_iters] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(grads)\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# `external_captures`.\u001b[39;00m\n\u001b[1;32m    664\u001b[0m grad_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    665\u001b[0m     name,\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: \u001b[43m_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    667\u001b[0m     args, {},\n\u001b[1;32m    668\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39m_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n\u001b[1;32m    669\u001b[0m                                        maximum_iterations, while_op,\n\u001b[1;32m    670\u001b[0m                                        body_graph_inputs, body_graph_outputs))\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;66;03m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m external_capture, internal_capture \u001b[38;5;129;01min\u001b[39;00m grad_func_graph\u001b[38;5;241m.\u001b[39mcaptures:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py:721\u001b[0m, in \u001b[0;36m_grad_fn\u001b[0;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[1;32m    714\u001b[0m grad_ys \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m3\u001b[39m:]\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# Build the gradient graph. Note that this builds the gradient computation of\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# func_graph in the current graph, which requires capturing tensors from\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;66;03m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;66;03m# after the forward While op has been rewritten in _resolve_grad_captures.\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# TODO(srbs): Mark GradientsHelper as public?\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m grad_outs \u001b[38;5;241m=\u001b[39m \u001b[43mgradients_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GradientsHelper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_ys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzero\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# is a tf.StopGradient in the loop body.\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grad_outs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:687\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m src_graph\u001b[38;5;241m.\u001b[39m_original_op(op):\n\u001b[1;32m    683\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    684\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[0;32m--> 687\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m \u001b[43m_MaybeCompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_scope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    693\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:327\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    324\u001b[0m     xla_compile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xla_compile:\n\u001b[0;32m--> 327\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exit early\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# together with the non-gradient computation.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:688\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m src_graph\u001b[38;5;241m.\u001b[39m_original_op(op):\n\u001b[1;32m    683\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    684\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 688\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    693\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/math_grad.py:1385\u001b[0m, in \u001b[0;36m_MulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1382\u001b[0m   gy \u001b[38;5;241m=\u001b[39m gen_math_ops\u001b[38;5;241m.\u001b[39mmul(x, grad)\n\u001b[1;32m   1383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1384\u001b[0m   gy \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m-> 1385\u001b[0m       math_ops\u001b[38;5;241m.\u001b[39mreduce_sum(\u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m, ry), sy)\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (gx, gy)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:6590\u001b[0m, in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6588\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m   6589\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m-> 6590\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6591\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMul\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6592\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m   6593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:795\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    790\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    791\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    793\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    794\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py:1012\u001b[0m, in \u001b[0;36m_WhileBodyGradFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (op_type \u001b[38;5;129;01min\u001b[39;00m optimized_reduction_ops \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m util\u001b[38;5;241m.\u001b[39moutput_all_intermediates() \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_graph \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m util\u001b[38;5;241m.\u001b[39mgraph_wrapped_for_higher_order_tape_gradients(\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_graph)):\n\u001b[1;32m   1002\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_op_to_forward_graph(\n\u001b[1;32m   1003\u001b[0m       op_type,\n\u001b[1;32m   1004\u001b[0m       inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1009\u001b[0m       op_def\u001b[38;5;241m=\u001b[39mop_def,\n\u001b[1;32m   1010\u001b[0m       compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m-> 1012\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_WhileBodyGradFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:668\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ctxt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ctxt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddValue\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    667\u001b[0m     inp \u001b[38;5;241m=\u001b[39m ctxt\u001b[38;5;241m.\u001b[39mAddValue(inp)\n\u001b[0;32m--> 668\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapture\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_create_op_internal(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:675\u001b[0m, in \u001b[0;36mFuncGraph.capture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcapture\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 675\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_captures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapture_by_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/core/function/capture/capture_container.py:150\u001b[0m, in \u001b[0;36mFunctionCaptures.capture_by_value\u001b[0;34m(self, graph, tensor, name)\u001b[0m\n\u001b[1;32m    147\u001b[0m     name \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    148\u001b[0m   \u001b[38;5;66;03m# cond/while graphs override _capture_helper() so cannot call\u001b[39;00m\n\u001b[1;32m    149\u001b[0m   \u001b[38;5;66;03m# self.create_placeholder_helper() here directly.\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py:1202\u001b[0m, in \u001b[0;36m_WhileBodyGradFuncGraph._capture_helper\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m   1198\u001b[0m captured_accumulator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(_WhileBodyGradFuncGraph, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_capture_helper(\n\u001b[1;32m   1199\u001b[0m     accumulator, name)\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# Pop the intermediate value from the tensor list in the gradient graph.\u001b[39;00m\n\u001b[0;32m-> 1202\u001b[0m new_tensor_list, captured_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mlist_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_list_pop_back\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaptured_accumulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indirect_captures[ops\u001b[38;5;241m.\u001b[39mtensor_id(tensor)] \u001b[38;5;241m=\u001b[39m captured_tensor\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_capture_to_output[ops\u001b[38;5;241m.\u001b[39mtensor_id(\n\u001b[1;32m   1207\u001b[0m     captured_accumulator)] \u001b[38;5;241m=\u001b[39m new_tensor_list\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/list_ops.py:108\u001b[0m, in \u001b[0;36mtensor_list_pop_back\u001b[0;34m(input_handle, element_dtype, name)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor_list_pop_back\u001b[39m(input_handle, element_dtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 108\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_list_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_list_pop_back\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_handle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m      \u001b[49m\u001b[43melement_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m      \u001b[49m\u001b[43melement_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/ops/gen_list_ops.py:698\u001b[0m, in \u001b[0;36mtensor_list_pop_back\u001b[0;34m(input_handle, element_shape, element_dtype, name)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m    697\u001b[0m element_dtype \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_type(element_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melement_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 698\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTensorListPopBack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_handle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m                           \u001b[49m\u001b[43melement_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m                           \u001b[49m\u001b[43melement_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:777\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mas_default(), ops\u001b[38;5;241m.\u001b[39mname_scope(name) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[1;32m    776\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fallback:\n\u001b[0;32m--> 777\u001b[0m     \u001b[43m_ExtractInputsAndAttrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_list_attr_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_type_attr_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m                           \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[1;32m    781\u001b[0m                            default_type_attr_map, attrs)\n\u001b[1;32m    782\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:686\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    683\u001b[0m     inferred_from[input_arg\u001b[38;5;241m.\u001b[39mtype_list_attr] \u001b[38;5;241m=\u001b[39m input_name\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    685\u001b[0m   \u001b[38;5;66;03m# single Tensor with specified type\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mbase_types\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_arg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m:\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnreachable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_arg\u001b[38;5;241m.\u001b[39mis_ref:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:263\u001b[0m, in \u001b[0;36mDType.__ne__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ne__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    262\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns True iff self != other.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__eq__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:253\u001b[0m, in \u001b[0;36mDType.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDType\u001b[49m:  \u001b[38;5;66;03m# pylint: disable=unidiomatic-typecheck\u001b[39;00m\n\u001b[1;32m    254\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     other \u001b[38;5;241m=\u001b[39m as_dtype(other)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attention_history=model.fit(X_train, Y_train, epochs = 25, batch_size = 64, verbose = 1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 7ms/step - loss: 0.6949 - accuracy: 0.4730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47303542494773865"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test,Y_test,verbose = 1)\n",
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_attention_create(optimizer = 'Adam',\n",
    "                 dropout_rate = 0.2, nb_filters = 256, kernel_size = 5,pool_size=2, units = 128,neurons = 20):\n",
    "    \n",
    "    seq_input = tf.keras.Input(shape=(100,))\n",
    "    e = Embedding(vocab_len, 100, input_length= 100)(seq_input)\n",
    "    conv1 = Conv1D(nb_filters,kernel_size,activation='relu',strides= 1, kernel_initializer='he_uniform')(e)\n",
    "    pool = MaxPooling1D(pool_size)(conv1)\n",
    "    dropout= Dropout(0.5)(pool)\n",
    "    lstm1 = Bidirectional(LSTM(10, return_sequences=True))(dropout)\n",
    "    att=attention()(lstm1)\n",
    "    dense1 = Dense(units = neurons, activation='relu', kernel_initializer='he_uniform')(att)\n",
    "    output= Dense(units = 1, activation = 'sigmoid', kernel_initializer= 'glorot_uniform')(dense1)\n",
    "    model=tf.keras.Model(seq_input,output) \n",
    "    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'units', 'class_weight'])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 8s - loss: 0.6929 - accuracy: 0.5118 - 8s/epoch - 116ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6892 - accuracy: 0.5436 - 3s/epoch - 39ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.6204 - accuracy: 0.6843 - 3s/epoch - 40ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.5497 - accuracy: 0.7118 - 3s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4954 - accuracy: 0.7812 - 3s/epoch - 39ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.4557 - accuracy: 0.7937 - 3s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.5052 - accuracy: 0.7624 - 3s/epoch - 39ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.4194 - accuracy: 0.8241 - 3s/epoch - 39ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.3719 - accuracy: 0.8414 - 3s/epoch - 39ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.3428 - accuracy: 0.8530 - 3s/epoch - 40ms/step\n",
      "17/17 - 1s - 988ms/epoch - 58ms/step\n",
      "[CV] END ...........................................units=10; total time=  32.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 7s - loss: 0.6931 - accuracy: 0.5022 - 7s/epoch - 115ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6863 - accuracy: 0.5494 - 3s/epoch - 43ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.6055 - accuracy: 0.6945 - 3s/epoch - 39ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.5168 - accuracy: 0.7730 - 3s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4319 - accuracy: 0.8289 - 3s/epoch - 39ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3711 - accuracy: 0.8602 - 3s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3190 - accuracy: 0.8819 - 3s/epoch - 39ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2834 - accuracy: 0.8930 - 3s/epoch - 39ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2502 - accuracy: 0.9089 - 3s/epoch - 40ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2349 - accuracy: 0.9147 - 3s/epoch - 39ms/step\n",
      "17/17 - 1s - 969ms/epoch - 57ms/step\n",
      "[CV] END ...........................................units=10; total time=  32.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 7s - loss: 0.6938 - accuracy: 0.5036 - 7s/epoch - 110ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6778 - accuracy: 0.5851 - 3s/epoch - 39ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.6008 - accuracy: 0.6959 - 3s/epoch - 39ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.5391 - accuracy: 0.7523 - 3s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4642 - accuracy: 0.8029 - 3s/epoch - 39ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.4021 - accuracy: 0.8347 - 3s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3662 - accuracy: 0.8569 - 3s/epoch - 39ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.3577 - accuracy: 0.8588 - 3s/epoch - 40ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.3118 - accuracy: 0.8829 - 3s/epoch - 39ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2996 - accuracy: 0.8872 - 3s/epoch - 40ms/step\n",
      "17/17 - 1s - 964ms/epoch - 57ms/step\n",
      "[CV] END ...........................................units=10; total time=  31.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 7s - loss: 0.6928 - accuracy: 0.5104 - 7s/epoch - 110ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6871 - accuracy: 0.5427 - 3s/epoch - 39ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.6003 - accuracy: 0.6964 - 3s/epoch - 39ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.4852 - accuracy: 0.7875 - 3s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4107 - accuracy: 0.8366 - 3s/epoch - 39ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3331 - accuracy: 0.8689 - 3s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.2838 - accuracy: 0.8916 - 3s/epoch - 39ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2556 - accuracy: 0.9027 - 3s/epoch - 39ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2354 - accuracy: 0.9123 - 3s/epoch - 39ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2270 - accuracy: 0.9099 - 3s/epoch - 40ms/step\n",
      "17/17 - 1s - 969ms/epoch - 57ms/step\n",
      "[CV] END ...........................................units=10; total time=  32.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 7s - loss: 0.6932 - accuracy: 0.5116 - 7s/epoch - 109ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6622 - accuracy: 0.6065 - 3s/epoch - 39ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.5624 - accuracy: 0.7211 - 3s/epoch - 39ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.4719 - accuracy: 0.7953 - 3s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.3966 - accuracy: 0.8372 - 3s/epoch - 39ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3345 - accuracy: 0.8622 - 3s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3038 - accuracy: 0.8878 - 3s/epoch - 39ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2718 - accuracy: 0.9022 - 3s/epoch - 39ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2395 - accuracy: 0.9104 - 3s/epoch - 40ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2232 - accuracy: 0.9191 - 3s/epoch - 40ms/step\n",
      "17/17 - 1s - 965ms/epoch - 57ms/step\n",
      "[CV] END ...........................................units=10; total time=  31.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 7s - loss: 0.6940 - accuracy: 0.5036 - 7s/epoch - 109ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 2s - loss: 0.6836 - accuracy: 0.5711 - 2s/epoch - 38ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 2s - loss: 0.5845 - accuracy: 0.7186 - 2s/epoch - 38ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 2s - loss: 0.4823 - accuracy: 0.7957 - 2s/epoch - 38ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4173 - accuracy: 0.8361 - 3s/epoch - 39ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3646 - accuracy: 0.8598 - 3s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3387 - accuracy: 0.8694 - 3s/epoch - 39ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2884 - accuracy: 0.8935 - 3s/epoch - 39ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2809 - accuracy: 0.8945 - 3s/epoch - 39ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 2s - loss: 0.2530 - accuracy: 0.9089 - 2s/epoch - 38ms/step\n",
      "17/17 - 1s - 981ms/epoch - 58ms/step\n",
      "[CV] END ...........................................units=20; total time=  31.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 8s - loss: 0.6951 - accuracy: 0.5007 - 8s/epoch - 129ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6882 - accuracy: 0.5547 - 3s/epoch - 44ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.6175 - accuracy: 0.6896 - 3s/epoch - 42ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.5019 - accuracy: 0.7836 - 3s/epoch - 40ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4272 - accuracy: 0.8265 - 3s/epoch - 41ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3567 - accuracy: 0.8694 - 3s/epoch - 42ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3248 - accuracy: 0.8795 - 3s/epoch - 44ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2842 - accuracy: 0.8978 - 3s/epoch - 44ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2601 - accuracy: 0.9012 - 3s/epoch - 40ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2434 - accuracy: 0.9137 - 3s/epoch - 39ms/step\n",
      "17/17 - 1s - 968ms/epoch - 57ms/step\n",
      "[CV] END ...........................................units=20; total time=  34.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 7s - loss: 0.6931 - accuracy: 0.5224 - 7s/epoch - 109ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6915 - accuracy: 0.5388 - 3s/epoch - 40ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.6466 - accuracy: 0.6414 - 3s/epoch - 39ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.5400 - accuracy: 0.7402 - 3s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4574 - accuracy: 0.8048 - 3s/epoch - 39ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.4038 - accuracy: 0.8337 - 3s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3427 - accuracy: 0.8641 - 3s/epoch - 39ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2945 - accuracy: 0.8872 - 3s/epoch - 40ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2611 - accuracy: 0.9012 - 3s/epoch - 44ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2387 - accuracy: 0.9084 - 3s/epoch - 42ms/step\n",
      "17/17 - 1s - 1s/epoch - 62ms/step\n",
      "[CV] END ...........................................units=20; total time=  32.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 8s - loss: 0.6934 - accuracy: 0.5113 - 8s/epoch - 116ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6709 - accuracy: 0.5933 - 3s/epoch - 40ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.5703 - accuracy: 0.7195 - 3s/epoch - 44ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.4700 - accuracy: 0.7952 - 3s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.3849 - accuracy: 0.8395 - 3s/epoch - 39ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3276 - accuracy: 0.8684 - 3s/epoch - 40ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.2901 - accuracy: 0.8954 - 3s/epoch - 38ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2540 - accuracy: 0.9022 - 3s/epoch - 39ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2396 - accuracy: 0.9113 - 3s/epoch - 39ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2184 - accuracy: 0.9186 - 3s/epoch - 39ms/step\n",
      "17/17 - 1s - 966ms/epoch - 57ms/step\n",
      "[CV] END ...........................................units=20; total time=  32.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 8s - loss: 0.6940 - accuracy: 0.5014 - 8s/epoch - 130ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6670 - accuracy: 0.5843 - 3s/epoch - 46ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.5528 - accuracy: 0.7288 - 3s/epoch - 40ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.4541 - accuracy: 0.8059 - 3s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.3983 - accuracy: 0.8319 - 3s/epoch - 42ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3419 - accuracy: 0.8598 - 3s/epoch - 40ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3069 - accuracy: 0.8762 - 3s/epoch - 39ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2690 - accuracy: 0.8897 - 3s/epoch - 40ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2688 - accuracy: 0.8969 - 3s/epoch - 40ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2387 - accuracy: 0.9118 - 3s/epoch - 39ms/step\n",
      "17/17 - 1s - 984ms/epoch - 58ms/step\n",
      "[CV] END ...........................................units=20; total time=  33.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 8s - loss: 0.6933 - accuracy: 0.5094 - 8s/epoch - 120ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6801 - accuracy: 0.5687 - 3s/epoch - 41ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.5897 - accuracy: 0.7051 - 3s/epoch - 41ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.4890 - accuracy: 0.7812 - 3s/epoch - 45ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4085 - accuracy: 0.8333 - 3s/epoch - 43ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3520 - accuracy: 0.8602 - 3s/epoch - 41ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3093 - accuracy: 0.8810 - 3s/epoch - 44ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2728 - accuracy: 0.8930 - 3s/epoch - 43ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2380 - accuracy: 0.9157 - 3s/epoch - 41ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2223 - accuracy: 0.9205 - 3s/epoch - 45ms/step\n",
      "17/17 - 1s - 1s/epoch - 61ms/step\n",
      "[CV] END ...........................................units=64; total time=  34.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 8s - loss: 0.6936 - accuracy: 0.5123 - 8s/epoch - 116ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6819 - accuracy: 0.5552 - 3s/epoch - 42ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.5970 - accuracy: 0.6853 - 3s/epoch - 45ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.4865 - accuracy: 0.7860 - 3s/epoch - 43ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4138 - accuracy: 0.8202 - 3s/epoch - 42ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3643 - accuracy: 0.8573 - 3s/epoch - 41ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3283 - accuracy: 0.8814 - 3s/epoch - 41ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2953 - accuracy: 0.8940 - 3s/epoch - 44ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2741 - accuracy: 0.9041 - 3s/epoch - 43ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2526 - accuracy: 0.9051 - 3s/epoch - 43ms/step\n",
      "17/17 - 1s - 1s/epoch - 64ms/step\n",
      "[CV] END ...........................................units=64; total time=  34.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 9s - loss: 0.6944 - accuracy: 0.4973 - 9s/epoch - 131ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6920 - accuracy: 0.5200 - 3s/epoch - 43ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.6477 - accuracy: 0.6414 - 3s/epoch - 42ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.5304 - accuracy: 0.7571 - 3s/epoch - 41ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4477 - accuracy: 0.8014 - 3s/epoch - 44ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3664 - accuracy: 0.8472 - 3s/epoch - 42ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3023 - accuracy: 0.8839 - 3s/epoch - 42ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2761 - accuracy: 0.8988 - 3s/epoch - 39ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2452 - accuracy: 0.9084 - 3s/epoch - 42ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2218 - accuracy: 0.9176 - 3s/epoch - 39ms/step\n",
      "17/17 - 1s - 1s/epoch - 59ms/step\n",
      "[CV] END ...........................................units=64; total time=  34.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 7s - loss: 0.6936 - accuracy: 0.5142 - 7s/epoch - 113ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6885 - accuracy: 0.5306 - 3s/epoch - 39ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.6141 - accuracy: 0.6882 - 3s/epoch - 40ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.5107 - accuracy: 0.7730 - 3s/epoch - 42ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4253 - accuracy: 0.8188 - 3s/epoch - 40ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3726 - accuracy: 0.8622 - 3s/epoch - 47ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3193 - accuracy: 0.8776 - 3s/epoch - 45ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.3113 - accuracy: 0.8829 - 3s/epoch - 44ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2973 - accuracy: 0.8925 - 3s/epoch - 43ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2750 - accuracy: 0.8940 - 3s/epoch - 45ms/step\n",
      "17/17 - 1s - 1s/epoch - 60ms/step\n",
      "[CV] END ...........................................units=64; total time=  34.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 8s - loss: 0.6925 - accuracy: 0.5217 - 8s/epoch - 116ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6687 - accuracy: 0.5829 - 3s/epoch - 41ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.5598 - accuracy: 0.7250 - 3s/epoch - 42ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.4691 - accuracy: 0.7962 - 3s/epoch - 43ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4033 - accuracy: 0.8314 - 3s/epoch - 44ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3457 - accuracy: 0.8613 - 3s/epoch - 45ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3101 - accuracy: 0.8815 - 3s/epoch - 46ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2816 - accuracy: 0.8858 - 3s/epoch - 45ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2521 - accuracy: 0.9085 - 3s/epoch - 43ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2342 - accuracy: 0.9114 - 3s/epoch - 40ms/step\n",
      "17/17 - 1s - 1s/epoch - 60ms/step\n",
      "[CV] END ...........................................units=64; total time=  34.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 7s - loss: 0.6923 - accuracy: 0.5190 - 7s/epoch - 112ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6538 - accuracy: 0.6260 - 3s/epoch - 44ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.5400 - accuracy: 0.7504 - 3s/epoch - 45ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.4711 - accuracy: 0.7952 - 3s/epoch - 44ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.3901 - accuracy: 0.8472 - 3s/epoch - 44ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3438 - accuracy: 0.8651 - 3s/epoch - 44ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3063 - accuracy: 0.8892 - 3s/epoch - 45ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2777 - accuracy: 0.9002 - 3s/epoch - 44ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2446 - accuracy: 0.9186 - 3s/epoch - 43ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2332 - accuracy: 0.9142 - 3s/epoch - 42ms/step\n",
      "17/17 - 1s - 1s/epoch - 62ms/step\n",
      "[CV] END ..........................................units=128; total time=  34.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 7s - loss: 0.6933 - accuracy: 0.5108 - 7s/epoch - 109ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6690 - accuracy: 0.6043 - 3s/epoch - 40ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.5728 - accuracy: 0.7123 - 3s/epoch - 39ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.4845 - accuracy: 0.7860 - 3s/epoch - 42ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4131 - accuracy: 0.8337 - 3s/epoch - 42ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3570 - accuracy: 0.8578 - 3s/epoch - 43ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3282 - accuracy: 0.8761 - 3s/epoch - 44ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2980 - accuracy: 0.8872 - 3s/epoch - 43ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2777 - accuracy: 0.8969 - 3s/epoch - 41ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2526 - accuracy: 0.9108 - 3s/epoch - 41ms/step\n",
      "17/17 - 1s - 1s/epoch - 69ms/step\n",
      "[CV] END ..........................................units=128; total time=  34.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 8s - loss: 0.6938 - accuracy: 0.5118 - 8s/epoch - 117ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 2s - loss: 0.6869 - accuracy: 0.5508 - 2s/epoch - 38ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.6111 - accuracy: 0.6858 - 3s/epoch - 41ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.5041 - accuracy: 0.7687 - 3s/epoch - 41ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4320 - accuracy: 0.8058 - 3s/epoch - 40ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3623 - accuracy: 0.8414 - 3s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 2s - loss: 0.3176 - accuracy: 0.8752 - 2s/epoch - 38ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2895 - accuracy: 0.8945 - 3s/epoch - 40ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 2s - loss: 0.2473 - accuracy: 0.9123 - 2s/epoch - 38ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 2s - loss: 0.2327 - accuracy: 0.9157 - 2s/epoch - 38ms/step\n",
      "17/17 - 1s - 948ms/epoch - 56ms/step\n",
      "[CV] END ..........................................units=128; total time=  32.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 7s - loss: 0.6931 - accuracy: 0.5166 - 7s/epoch - 115ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6842 - accuracy: 0.5528 - 3s/epoch - 41ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.6092 - accuracy: 0.6853 - 3s/epoch - 41ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.4996 - accuracy: 0.7812 - 3s/epoch - 42ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4166 - accuracy: 0.8246 - 3s/epoch - 50ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3424 - accuracy: 0.8607 - 3s/epoch - 45ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.2981 - accuracy: 0.8834 - 3s/epoch - 43ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2685 - accuracy: 0.8978 - 3s/epoch - 46ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2493 - accuracy: 0.9036 - 3s/epoch - 40ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2107 - accuracy: 0.9210 - 3s/epoch - 41ms/step\n",
      "17/17 - 1s - 984ms/epoch - 58ms/step\n",
      "[CV] END ..........................................units=128; total time=  34.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 - 8s - loss: 0.6942 - accuracy: 0.5096 - 8s/epoch - 123ms/step\n",
      "Epoch 2/10\n",
      "65/65 - 3s - loss: 0.6848 - accuracy: 0.5559 - 3s/epoch - 41ms/step\n",
      "Epoch 3/10\n",
      "65/65 - 3s - loss: 0.6009 - accuracy: 0.6961 - 3s/epoch - 39ms/step\n",
      "Epoch 4/10\n",
      "65/65 - 3s - loss: 0.5030 - accuracy: 0.7669 - 3s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "65/65 - 3s - loss: 0.4392 - accuracy: 0.8107 - 3s/epoch - 39ms/step\n",
      "Epoch 6/10\n",
      "65/65 - 3s - loss: 0.3916 - accuracy: 0.8377 - 3s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "65/65 - 3s - loss: 0.3288 - accuracy: 0.8695 - 3s/epoch - 39ms/step\n",
      "Epoch 8/10\n",
      "65/65 - 3s - loss: 0.2939 - accuracy: 0.8834 - 3s/epoch - 39ms/step\n",
      "Epoch 9/10\n",
      "65/65 - 3s - loss: 0.2440 - accuracy: 0.9114 - 3s/epoch - 42ms/step\n",
      "Epoch 10/10\n",
      "65/65 - 3s - loss: 0.2353 - accuracy: 0.9099 - 3s/epoch - 41ms/step\n",
      "17/17 - 1s - 977ms/epoch - 57ms/step\n",
      "[CV] END ..........................................units=128; total time=  33.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 - 8s - loss: 0.6936 - accuracy: 0.5112 - 8s/epoch - 95ms/step\n",
      "Epoch 2/10\n",
      "82/82 - 3s - loss: 0.6637 - accuracy: 0.5875 - 3s/epoch - 40ms/step\n",
      "Epoch 3/10\n",
      "82/82 - 3s - loss: 0.5452 - accuracy: 0.7394 - 3s/epoch - 39ms/step\n",
      "Epoch 4/10\n",
      "82/82 - 3s - loss: 0.4530 - accuracy: 0.8069 - 3s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "82/82 - 3s - loss: 0.3932 - accuracy: 0.8389 - 3s/epoch - 39ms/step\n",
      "Epoch 6/10\n",
      "82/82 - 3s - loss: 0.3543 - accuracy: 0.8608 - 3s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "82/82 - 3s - loss: 0.3020 - accuracy: 0.8859 - 3s/epoch - 40ms/step\n",
      "Epoch 8/10\n",
      "82/82 - 3s - loss: 0.2659 - accuracy: 0.9017 - 3s/epoch - 39ms/step\n",
      "Epoch 9/10\n",
      "82/82 - 3s - loss: 0.2489 - accuracy: 0.9056 - 3s/epoch - 39ms/step\n",
      "Epoch 10/10\n",
      "82/82 - 3s - loss: 0.2215 - accuracy: 0.9156 - 3s/epoch - 39ms/step\n",
      "Best accuracy:  0.804167503589469\n",
      "Best parameters:  {'units': 128}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'units': [10,20,64,128]\n",
    "    # 'units': [10]\n",
    "\n",
    "}                                                             ####perform grid search to find the hyperparameters\n",
    "\n",
    "model = KerasClassifier(build_fn = model_attention_create, verbose = 2,units = [10,20,64,128])\n",
    "print(model.get_params().keys())\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2)\n",
    "grid_results = grid_search.fit(X_train, Y_train, epochs = 10)\n",
    "print('Best accuracy: ', grid_results.best_score_)\n",
    "print('Best parameters: ', grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter kernel_size for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(kernel_size=3)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn \u001b[38;5;241m=\u001b[39m model_attention_create, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      9\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m model, param_grid \u001b[38;5;241m=\u001b[39m param_grid, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m grid_results \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest accuracy: \u001b[39m\u001b[38;5;124m'\u001b[39m, grid_results\u001b[38;5;241m.\u001b[39mbest_score_)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;124m'\u001b[39m, grid_results\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:717\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    710\u001b[0m fit_params \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params, train)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;66;03m# here we clone the parameters, since sometimes the parameters\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;66;03m# themselves might be estimators, e.g. when we search over different\u001b[39;00m\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;66;03m# estimators in a pipeline.\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;66;03m# ref: https://github.com/scikit-learn/scikit-learn/pull/26786\u001b[39;00m\n\u001b[0;32m--> 717\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    721\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audenv称/lib/python3.8/site-packages/scikeras/wrappers.py:1165\u001b[0m, in \u001b[0;36mBaseWrapper.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{param: value})\n\u001b[1;32m   1162\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   1163\u001b[0m             \u001b[38;5;66;03m# Give a SciKeras specific user message to aid\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m             \u001b[38;5;66;03m# in moving from the Keras wrappers\u001b[39;00m\n\u001b[0;32m-> 1165\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1166\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1167\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis issue can likely be resolved by setting this parameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1168\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m constructor:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1169\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1170\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheck the list of available parameters with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1171\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `estimator.get_params().keys()`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1172\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter kernel_size for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(kernel_size=3)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'nb_filters': [128,256],\n",
    "    'kernel_size':[3,5],\n",
    "    'pool_size':[2,4]\n",
    "\n",
    "}                                                             ####perform grid search to find the hyperparameters\n",
    "\n",
    "model = KerasClassifier(build_fn = model_attention_create, verbose = 2)\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2)\n",
    "grid_results = grid_search.fit(X_train, Y_train, epochs = 10)\n",
    "print('Best accuracy: ', grid_results.best_score_)\n",
    "print('Best parameters: ', grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'neurons':[10,20,64,128]\n",
    "}                                                             ####perform grid search to find the hyperparameters\n",
    "\n",
    "model = KerasClassifier(build_fn = model_attention_create, verbose = 2)\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2)\n",
    "grid_results = grid_search.fit(X_train, Y_train, epochs = 10)\n",
    "print('Best accuracy: ', grid_results.best_score_)\n",
    "print('Best parameters: ', grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'dropout_rate':[0.1,0.2,0.3,0.4,0.5]\n",
    "}                                                             ####perform grid search to find the hyperparameters\n",
    "\n",
    "model = KerasClassifier(build_fn = model_attention_create, verbose = 2)\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2)\n",
    "grid_results = grid_search.fit(X_train, Y_train, epochs = 10)\n",
    "print('Best accuracy: ', grid_results.best_score_)\n",
    "print('Best parameters: ', grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'batch_size':[32,64,128,256]\n",
    "}                                                             ####perform grid search to find the hyperparameters\n",
    "\n",
    "model = KerasClassifier(build_fn = model_attention_create, verbose = 2)\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2, cv=2)\n",
    "grid_results = grid_search.fit(X_train, Y_train, epochs = 10)\n",
    "print('Best accuracy: ', grid_results.best_score_)\n",
    "print('Best parameters: ', grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL with Optimised Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_input = keras.Input(shape=(100,))\n",
    "e = Embedding(vocab_len, 100, input_length= 100)(seq_input)\n",
    "conv1 = Conv1D(filters=256,kernel_size=5,activation='relu',strides= 1, kernel_initializer='he_uniform')(e)\n",
    "pool = MaxPooling1D(pool_size=4)(conv1)\n",
    "dropout= Dropout(0.5)(pool)\n",
    "lstm1 = Bidirectional(LSTM(64, return_sequences=True))(dropout)\n",
    "att=attention()(lstm1)\n",
    "dense1 = Dense(units = 128, activation='relu', kernel_initializer='he_uniform')(att)\n",
    "output= Dense(units = 1, activation = 'sigmoid', kernel_initializer= 'glorot_uniform')(dense1)\n",
    "att_model=keras.Model(seq_input,output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_history=att_model.fit(X_train, Y_train, epochs = 50, batch_size = 32, verbose = 1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = att_model.evaluate(X_test,Y_test,verbose = 1)\n",
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                             ###plot loss on train and val data\n",
    "plt.plot(attention_history.history['loss'])\n",
    "plt.plot(attention_history.history['val_loss'])\n",
    "plt.title('Model Loss Plot')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'],loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_model.save('attention_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_model.load_weights('attention_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = att_model.predict(X_test)\n",
    "Y_pred = (Y_pred >0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(Y_test,Y_pred)        ###Model evaluation\n",
    "precision = precision_score(Y_test,Y_pred)\n",
    "recall = recall_score(Y_test,Y_pred)\n",
    "F1 = f1_score(Y_test,Y_pred)\n",
    "specificity = (confusion[0][0]/(confusion[0][0]+confusion[0][1]))\n",
    "print('confusion matrix {}'.format(confusion))\n",
    "print('precision is {}'.format(precision))\n",
    "print('recall is  {}'.format(recall))\n",
    "print('F1 score {}'.format(F1))\n",
    "print('specificity is {}'.format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_proba = att_model.predict(X_test)\n",
    "fpr, tpr, _ = roc_curve(Y_test, Y_pred_proba)\n",
    "auc = roc_auc_score(Y_test, Y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention MODEL: Case 2 - Using Pretrained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = dict()                                 ##read glove vector file\n",
    "f = open('../glove.6B.100d.txt',encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vectors = np.asarray(values[1:],dtype='float32')\n",
    "    embeddings[word]=vectors\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_len, 100))      ###create a matrix consist of words and its vectors\n",
    "for word, i in train_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_input = keras.Input(shape=(100,))\n",
    "e = Embedding(vocab_len, 100, input_length= 100,weights = [embedding_matrix], trainable= False)(seq_input)\n",
    "conv1 = Conv1D(filters=256,kernel_size=5,activation='relu',strides= 1, kernel_initializer='he_uniform')(e)\n",
    "pool = MaxPooling1D(pool_size=4)(conv1)\n",
    "dropout= Dropout(0.5)(pool)\n",
    "lstm1 = Bidirectional(LSTM(64, return_sequences=True))(dropout)\n",
    "att=attention()(lstm1)\n",
    "dense1 = Dense(units = 128, activation='relu', kernel_initializer='he_uniform')(att)\n",
    "output= Dense(units = 1, activation = 'sigmoid', kernel_initializer= 'glorot_uniform')(dense1)\n",
    "att_model1=keras.Model(seq_input,output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_model1.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_history=att_model1.fit(X_train, Y_train, epochs = 50, batch_size = 32, verbose = 1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = att_model1.evaluate(X_test,Y_test,verbose = 1)\n",
    "score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_attention1_create(optimizer = 'Adam',\n",
    "                 dropout_rate = 0.2, nb_filters = 256, kernel_size = 5,pool_size=2,units = 128,neurons = 20):\n",
    "    \n",
    "    seq_input = keras.Input(shape=(100,))\n",
    "    e = Embedding(vocab_len, 100, input_length= 100,weights = [embedding_matrix], trainable= False)(seq_input)\n",
    "    conv1 = Conv1D(nb_filters,kernel_size,activation='relu',strides= 1, kernel_initializer='he_uniform')(e)\n",
    "    pool = MaxPooling1D(pool_size)(conv1)\n",
    "    dropout= Dropout(0.5)(pool)\n",
    "    lstm1 = Bidirectional(LSTM(10, return_sequences=True))(dropout)\n",
    "    att=attention()(lstm1)\n",
    "    dense1 = Dense(units = neurons, activation='relu', kernel_initializer='he_uniform')(att)\n",
    "    output= Dense(units = 1, activation = 'sigmoid', kernel_initializer= 'glorot_uniform')(dense1)\n",
    "    model=keras.Model(seq_input,output) \n",
    "    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'nb_filters': [128,256],\n",
    "    'kernel_size':[3,5],\n",
    "    'pool_size':[2,4]\n",
    "\n",
    "}                                                             ####perform grid search to find the hyperparameters\n",
    "\n",
    "model = KerasClassifier(build_fn = model_attention1_create, verbose = 2)\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2)\n",
    "grid_results = grid_search.fit(X_train, Y_train, epochs = 10)\n",
    "print('Best accuracy: ', grid_results.best_score_)\n",
    "print('Best parameters: ', grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'neurons':[10,20,64,128]\n",
    "\n",
    "}                                                             ####perform grid search to find the hyperparameters\n",
    "\n",
    "model = KerasClassifier(build_fn = model_attention1_create, verbose = 2)\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2)\n",
    "grid_results = grid_search.fit(X_train, Y_train, epochs = 10)\n",
    "print('Best accuracy: ', grid_results.best_score_)\n",
    "print('Best parameters: ', grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'dropout_rate':[0.1,0.2,0.3,0.4,0.5]\n",
    "\n",
    "}                                                             ####perform grid search to find the hyperparameters\n",
    "\n",
    "model = KerasClassifier(build_fn = model_attention1_create, verbose = 2)\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2)\n",
    "grid_results = grid_search.fit(X_train, Y_train, epochs = 10)\n",
    "print('Best accuracy: ', grid_results.best_score_)\n",
    "print('Best parameters: ', grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'units': [10,20,64,128]\n",
    "}                                                             ####perform grid search to find the hyperparameters\n",
    "\n",
    "model = KerasClassifier(build_fn = model_attention1_create, verbose = 2)\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 2)\n",
    "grid_results = grid_search.fit(X_train, Y_train, epochs = 10)\n",
    "print('Best accuracy: ', grid_results.best_score_)\n",
    "print('Best parameters: ', grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL with Optimised Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_input = keras.Input(shape=(100,))\n",
    "e = Embedding(vocab_len, 100, input_length= 100,weights = [embedding_matrix], trainable= False)(seq_input)\n",
    "conv1 = Conv1D(filters=256,kernel_size=5,activation='relu',strides= 1, kernel_initializer='he_uniform')(e)\n",
    "pool = MaxPooling1D(pool_size=4)(conv1)\n",
    "dropout= Dropout(0.5)(pool)\n",
    "lstm1 = Bidirectional(LSTM(20, return_sequences=True))(dropout)\n",
    "att=attention()(lstm1)\n",
    "dense1 = Dense(units = 128, activation='relu', kernel_initializer='he_uniform')(att)\n",
    "output= Dense(units = 1, activation = 'sigmoid', kernel_initializer= 'glorot_uniform')(dense1)\n",
    "att_model2=keras.Model(seq_input,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_model2.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_history=att_model2.fit(X_train, Y_train, epochs = 50, batch_size = 32, verbose = 1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = att_model2.evaluate(X_test,Y_test,verbose = 1)\n",
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                             ###plot loss on train and val data\n",
    "plt.plot(attention_history.history['loss'])\n",
    "plt.plot(attention_history.history['val_loss'])\n",
    "plt.title('Model Loss Plot')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'],loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_model2.save('attention_pretrained.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_model2.load_weights('attention_pretrained.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = att_model2.predict(X_test)\n",
    "Y_pred = (Y_pred >0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(Y_test,Y_pred)        ###Model evaluation\n",
    "precision = precision_score(Y_test,Y_pred)\n",
    "recall = recall_score(Y_test,Y_pred)\n",
    "F1 = f1_score(Y_test,Y_pred)\n",
    "specificity = (confusion[0][0]/(confusion[0][0]+confusion[0][1]))\n",
    "print('confusion matrix {}'.format(confusion))\n",
    "print('precision is {}'.format(precision))\n",
    "print('recall is  {}'.format(recall))\n",
    "print('F1 score {}'.format(F1))\n",
    "print('specificity is {}'.format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_proba = att_model2.predict(X_test)\n",
    "fpr, tpr, _ = roc_curve(Y_test, Y_pred_proba)\n",
    "auc = roc_auc_score(Y_test, Y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
